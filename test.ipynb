{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4473)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(r\"D:\\Project\\Datasets\\randomSampling_bone_controller\\npy2\\dataBoneSet103.npy\").shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.vision import transforms as T\n",
    "import numpy as np\n",
    "from dataset import JointCtrl\n",
    "import os\n",
    "value_0 = np.load(\"./value_0.npy\")\n",
    "mean = np.array([0.00174034, -0.0296329, 0.08699034, 0.4884157, 0.13937208, 0.1928098], dtype=np.float64)\n",
    "std = np.array([0.47395173, 0.5340112, 0.62341311, 17.59106008, 7.27811802, 9.06478785], dtype=np.float64)\n",
    "def get_train_transforms():\n",
    "    return T.Compose([\n",
    "        # T.ToTensor(),\n",
    "        T.Normalize(mean=mean, std=std),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = r'D:\\Project\\Datasets\\randomSampling'\n",
    "data_len = 10\n",
    "joint_path_list = []\n",
    "ctrl_path_list = []\n",
    "transform = get_train_transforms()\n",
    "for i in range(data_len):\n",
    "    joint_path_list.append(os.path.join(data_root_path, f\"dataBoneSet{i}.npy\"))\n",
    "    ctrl_path_list.append(os.path.join(data_root_path, f\"dataCtrlSet_{i}.npy\"))\n",
    "\n",
    "# data = JointCtrl(joint_path_list, ctrl_path_list)\n",
    "dataset_train = JointCtrl(joint_path_list[:int(0.8*data_len)], \n",
    "                            ctrl_path_list[:int(0.8*data_len)], \n",
    "                            transform=transform,\n",
    "                            value_0=value_0)\n",
    "dataset_val = JointCtrl(joint_path_list[int(0.8*data_len):], \n",
    "                            ctrl_path_list[int(0.8*data_len):], \n",
    "                            transform=transform,\n",
    "                            value_0=value_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_100 = (np.load(joint_path_list[0])-value_0)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(joint_100[600:606]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.__getitem__(100)[0][:,0,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = (data_list[3] - mean.reshape((6,1,1))) / std.reshape((6,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "label_list = []\n",
    "for joint_path, ctrl_path in zip(joint_path_list, ctrl_path_list):\n",
    "    # d1 = np.load(joint_path).astype(dtype=np.float32)\n",
    "    # print(d1[0][-16:])\n",
    "    d = np.load(joint_path) - value_0\n",
    "    data_list.extend(d.reshape(1000, 1, -1, 6)\n",
    "                        .transpose(0, 3, 1, 2))\n",
    "    label_list.extend(np.load(ctrl_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[0] =(data_list[0] - mean.reshape((6,1,1))) / std.reshape((6,1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = np.array(data_list)\n",
    "print(data_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对data随机取1000个样本，计算均值和方差\n",
    "data = data_\n",
    "# data = data_[np.random.choice(data_.shape[0], 50000, replace=False), :, :, :]\n",
    "# 计算data第2维的均值和方差\n",
    "mean = np.mean(data, axis=(0, 2, 3), keepdims=False)\n",
    "std = np.std(data, axis=(0, 2, 3), keepdims=False)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data_list)\n",
    "j = 30\n",
    "data[1000,:,0,1]==dataset_train.__getitem__(2)[0][:,0,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.load(joint_path_list[0]).astype(dtype=np.float32)\n",
    "d2 = d1.reshape(1000, 1, -1, 6)\n",
    "d3 = d2.transpose(0, 3, 1, 2)\n",
    "d3[0, :, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将data第二维转为(6,1,-1)\n",
    "data = data.reshape(data.shape[0], 1, -1, 6).transpose(0,3,1,2)\n",
    "data[0,:,0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "value_0 = np.load(\"./value_0.npy\")\n",
    "joint = np.loadtxt('./Pia_jointAnimation.txt')-value_0\n",
    "ctrl = np.loadtxt('./Pia_ctrlAnimation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model\n",
    "import paddle\n",
    "model = build_model(model_name='resnet18', in_features=6, out_features=220)\n",
    "model_state = paddle.load(\"./output/epoch_1000/model.pdparams\")\n",
    "model.set_dict(model_state)\n",
    "model_jit = paddle.jit.to_static(model)\n",
    "paddle.jit.save(model_jit, \"./inference/model\", input_spec=[paddle.static.InputSpec(shape=[None, 6, 887, 6], name=\"x\",dtype='float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "paddle.enable_static()\n",
    "exe = paddle.static.Executor(paddle.CPUPlace())\n",
    "[inference_program, feed_target_names, fetch_targets] = (paddle.static.load_inference_model('./inference/model', exe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.vision import transforms as T\n",
    "\n",
    "def get_train_transforms():\n",
    "    return T.Compose([\n",
    "        # T.ToTensor(),\n",
    "        T.Normalize(mean=[0.00174034, -0.0296329, 0.08699034, 0.4884157, 0.13937208, 0.1928098], \n",
    "                    std=[0.47395173, 0.5340112, 0.62341311, 17.59106008, 7.27811802, 9.06478785])])\n",
    "transform = get_train_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiont_test = joint[0].reshape(-1,6)\n",
    "jiont_test_ = jiont_test[np.newaxis, :]\n",
    "\n",
    "# 将joint_test_第三维标准化\n",
    "jiont_test__ = transform(jiont_test_)\n",
    "jiont_test__ = jiont_test__.reshape(1,6,887,6).astype(np.float32)\n",
    "# jiont_test__ = np.array([jiont_test__], dtype=np.float32)\n",
    "# jiont_test__ = paddle.to_tensor(jiont_test__, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = exe.run(inference_program,\n",
    "                feed={feed_target_names[0]: jiont_test__},\n",
    "                fetch_list=fetch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43896cd43067d526f9a594a9f15bd98d73968aebdd4ebc3c7b100c60540a89e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
